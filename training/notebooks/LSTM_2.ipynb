{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2791cee",
   "metadata": {},
   "source": [
    "# LSTM Model for EMG to Finger Position Prediction\n",
    "\n",
    "This notebook trains an LSTM model to predict finger positions from EMG sensor data.\n",
    "\n",
    "## Pipeline Overview:\n",
    "\n",
    "1. Load and clean data\n",
    "1. Create temporal sequences\n",
    "1. Split into train/test sets (80/20)\n",
    "1. Train LSTM model with proper batching\n",
    "1. Evaluate on unseen test data\n",
    "1. Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db411870",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hei\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c32eb7d",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4028103d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Grip (Python 3.12.7)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f53521",
   "metadata": {},
   "source": [
    "## 2. Load and Clean Data\n",
    "\n",
    "Load CSV data and handle corrupted rows where sensor values are missing or misaligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d513753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "path = os.path.join(\"../../data\", \"integrated_data_20251030_195505.csv\")\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RAW DATA INFO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst 3 rows:\\n{df.head(3)}\")\n",
    "\n",
    "# Define required numeric columns (excluding timestamp and hand_label)\n",
    "numeric_columns = ['iteration', 'env0', 'raw0', 'env1', 'raw1', 'env2', 'raw2', 'env3', 'raw3', \n",
    "                   'thumb_tip', 'thumb_base', 'index', 'middle', 'ring', 'pinky']\n",
    "\n",
    "# Convert all numeric columns, coercing errors to NaN (handles corrupted rows)\n",
    "for col in numeric_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Remove rows with any NaN values in numeric columns\n",
    "df_clean = df.dropna(subset=numeric_columns)\n",
    "\n",
    "print(f\"\\nRows removed (corrupted/missing data): {len(df) - len(df_clean)}\")\n",
    "print(f\"Clean data shape: {df_clean.shape}\")\n",
    "\n",
    "# Extract only numeric data (drop timestamp and hand_label)\n",
    "data = df_clean[numeric_columns].values.astype(np.float32)\n",
    "\n",
    "print(f\"\\nFinal numeric data shape: {data.shape}\")\n",
    "print(f\"Data statistics:\\n{pd.DataFrame(data, columns=numeric_columns).describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6f8104",
   "metadata": {},
   "source": [
    "## 3. Prepare Data for LSTM\n",
    "\n",
    "Separate sensor inputs from finger outputs and create temporal sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ff884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sensor (input) and finger (output) columns\n",
    "sensor_columns = ['env0', 'raw0', 'env1', 'raw1', 'env2', 'raw2', 'env3', 'raw3']\n",
    "finger_columns = ['thumb_tip', 'thumb_base', 'index', 'middle', 'ring', 'pinky']\n",
    "\n",
    "# Get column indices in the data array\n",
    "sensor_indices = [numeric_columns.index(col) for col in sensor_columns]\n",
    "finger_indices = [numeric_columns.index(col) for col in finger_columns]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATA CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Sensor columns (inputs): {sensor_columns}\")\n",
    "print(f\"Sensor indices: {sensor_indices}\")\n",
    "print(f\"Number of input features: {len(sensor_indices)}\")\n",
    "print(f\"\\nFinger columns (outputs): {finger_columns}\")\n",
    "print(f\"Finger indices: {finger_indices}\")\n",
    "print(f\"Number of output features: {len(finger_indices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594b6750",
   "metadata": {},
   "source": [
    "## 4. Create Temporal Sequences\n",
    "\n",
    "LSTMs need sequences of data. We'll create sliding windows of sensor readings to predict the next finger position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99a23ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length):\n",
    "    \"\"\"\n",
    "    Create sequences for LSTM training.\n",
    "    \n",
    "    Args:\n",
    "        data: numpy array of shape (num_samples, num_features)\n",
    "        seq_length: length of input sequence\n",
    "    \n",
    "    Returns:\n",
    "        X: sequences of shape (num_sequences, seq_length, num_features)\n",
    "        y: targets of shape (num_sequences, num_features)\n",
    "    \"\"\"\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:i + seq_length, :]  # Sequence of seq_length time steps\n",
    "        y = data[i + seq_length, :]    # Next time step (target)\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Create sequences\n",
    "seq_length = 15\n",
    "X, y = create_sequences(data, seq_length)\n",
    "\n",
    "print(f\"\\nSequence length: {seq_length} time steps\")\n",
    "print(f\"Total sequences created: {len(X)}\")\n",
    "print(f\"X shape: {X.shape} (num_sequences, seq_length, num_features)\")\n",
    "print(f\"y shape: {y.shape} (num_sequences, num_features)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844959d6",
   "metadata": {},
   "source": [
    "## 5. Train/Test Split and Feature Selection\n",
    "\n",
    "Split data temporally (80/20) and separate sensor inputs from finger outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e25aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data temporally (80% train, 20% test)\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(X) * split_ratio)\n",
    "\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAIN/TEST SPLIT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total sequences: {len(X)}\")\n",
    "print(f\"Training sequences: {len(X_train)} ({split_ratio*100:.0f}%)\")\n",
    "print(f\"Testing sequences: {len(X_test)} ({(1-split_ratio)*100:.0f}%)\")\n",
    "\n",
    "# Extract sensor and finger features\n",
    "trainX = torch.tensor(X_train[:, :, sensor_indices], dtype=torch.float32)\n",
    "trainY = torch.tensor(y_train[:, finger_indices], dtype=torch.float32)\n",
    "testX = torch.tensor(X_test[:, :, sensor_indices], dtype=torch.float32)\n",
    "testY = torch.tensor(y_test[:, finger_indices], dtype=torch.float32)\n",
    "\n",
    "print(f\"\\nTraining data:\")\n",
    "print(f\"  trainX: {trainX.shape} (sequences, seq_length, input_features)\")\n",
    "print(f\"  trainY: {trainY.shape} (sequences, output_features)\")\n",
    "print(f\"\\nTesting data:\")\n",
    "print(f\"  testX: {testX.shape}\")\n",
    "print(f\"  testY: {testY.shape}\")\n",
    "\n",
    "print(f\"\\nInput features: {len(sensor_indices)}\")\n",
    "print(f\"Output features: {len(finger_indices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d3d316",
   "metadata": {},
   "source": [
    "## 6. Normalize Data\n",
    "\n",
    "Normalize inputs and outputs for better training stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34fe002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize sensor data (inputs)\n",
    "scaler_X = StandardScaler()\n",
    "trainX_reshaped = trainX.reshape(-1, trainX.shape[-1]).numpy()\n",
    "trainX_scaled = scaler_X.fit_transform(trainX_reshaped).reshape(trainX.shape)\n",
    "trainX = torch.tensor(trainX_scaled, dtype=torch.float32)\n",
    "\n",
    "testX_reshaped = testX.reshape(-1, testX.shape[-1]).numpy()\n",
    "testX_scaled = scaler_X.transform(testX_reshaped).reshape(testX.shape)\n",
    "testX = torch.tensor(testX_scaled, dtype=torch.float32)\n",
    "\n",
    "# Normalize finger data (outputs)\n",
    "scaler_Y = StandardScaler()\n",
    "trainY_scaled = scaler_Y.fit_transform(trainY.numpy())\n",
    "trainY = torch.tensor(trainY_scaled, dtype=torch.float32)\n",
    "\n",
    "testY_scaled = scaler_Y.transform(testY.numpy())\n",
    "testY = torch.tensor(testY_scaled, dtype=torch.float32)\n",
    "\n",
    "print(\"âœ“ Data normalized using StandardScaler\")\n",
    "print(f\"  Sensor mean: {scaler_X.mean_[:3].round(2)} (first 3 features)\")\n",
    "print(f\"  Sensor std: {scaler_X.scale_[:3].round(2)} (first 3 features)\")\n",
    "print(f\"  Finger mean: {scaler_Y.mean_[:3].round(2)} (first 3 features)\")\n",
    "print(f\"  Finger std: {scaler_Y.scale_[:3].round(2)} (first 3 features)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8089483",
   "metadata": {},
   "source": [
    "## 7. Define LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75474591",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout=0.2):\n",
    "        \"\"\"\n",
    "        LSTM model for sequence prediction.\n",
    "        \n",
    "        Args:\n",
    "            input_dim: Number of input features\n",
    "            hidden_dim: Number of hidden units in LSTM\n",
    "            layer_dim: Number of LSTM layers\n",
    "            output_dim: Number of output features\n",
    "            dropout: Dropout probability for regularization\n",
    "        \"\"\"\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # LSTM layer with dropout between layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim, \n",
    "            hidden_dim, \n",
    "            layer_dim, \n",
    "            batch_first=True,\n",
    "            dropout=dropout if layer_dim > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Fully connected output layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden and cell states (set to zeros)\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
    "        \n",
    "        # LSTM forward pass\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Take the last time step output\n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        # Apply dropout\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Model hyperparameters\n",
    "input_dim = len(sensor_indices)  # Number of sensor features\n",
    "hidden_dim = 128                  # Number of hidden units\n",
    "layer_dim = 2                     # Number of LSTM layers\n",
    "output_dim = len(finger_indices)  # Number of finger features\n",
    "dropout = 0.2                     # Dropout probability\n",
    "\n",
    "# Initialize model\n",
    "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim, dropout)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL ARCHITECTURE\")\n",
    "print(\"=\"*60)\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18961e3",
   "metadata": {},
   "source": [
    "## 8. Setup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7978df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min', \n",
    "    factor=0.5, \n",
    "    patience=10, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Create DataLoader for batching\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(trainX, trainY)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Loss function: MSELoss\")\n",
    "print(f\"Optimizer: Adam (lr=0.001)\")\n",
    "print(f\"Scheduler: ReduceLROnPlateau (factor=0.5, patience=10)\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Batches per epoch: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66b1670",
   "metadata": {},
   "source": [
    "## 9. Train Model\n",
    "\n",
    "Train with proper batching, validation tracking, and early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb95968",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "patience = 20\n",
    "patience_counter = 0\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING STARTED\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for batch_X, batch_Y in train_loader:\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, batch_Y)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Average training loss\n",
    "    avg_train_loss = epoch_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(testX)\n",
    "        val_loss = criterion(val_outputs, testY)\n",
    "        val_losses.append(val_loss.item())\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Early stopping check\n",
    "    if val_loss.item() < best_val_loss:\n",
    "        best_val_loss = val_loss.item()\n",
    "        patience_counter = 0\n",
    "        # Save best model\n",
    "        torch.save(model.state_dict(), \"../../models/best_lstm_model.pth\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "              f'Train Loss: {avg_train_loss:.4f}, '\n",
    "              f'Val Loss: {val_loss.item():.4f}, '\n",
    "              f'Best Val: {best_val_loss:.4f}')\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"\\nEarly stopping triggered at epoch {epoch+1}\")\n",
    "        print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "        break\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETED\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Final train loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Final validation loss: {val_losses[-1]:.4f}\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load(\"../../models/best_lstm_model.pth\"))\n",
    "print(\"\\nâœ“ Best model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d524c8",
   "metadata": {},
   "source": [
    "## 10. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8d873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.plot(train_losses, label='Train Loss', alpha=0.8, linewidth=2)\n",
    "plt.plot(val_losses, label='Validation Loss', alpha=0.8, linewidth=2)\n",
    "plt.axhline(y=best_val_loss, color='r', linestyle='--', label=f'Best Val Loss ({best_val_loss:.4f})', alpha=0.5)\n",
    "\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss (MSE)', fontsize=12)\n",
    "plt.title('Training vs Validation Loss', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check for overfitting\n",
    "final_gap = val_losses[-1] - train_losses[-1]\n",
    "if final_gap > 0.1:\n",
    "    print(f\"âš  Warning: Possible overfitting detected (gap: {final_gap:.4f})\")\n",
    "else:\n",
    "    print(f\"âœ“ Good generalization (train-val gap: {final_gap:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c872df7",
   "metadata": {},
   "source": [
    "## 11. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44abf160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions_scaled = model(testX).numpy()\n",
    "    actual_scaled = testY.numpy()\n",
    "\n",
    "# Inverse transform to original scale\n",
    "predictions = scaler_Y.inverse_transform(predictions_scaled)\n",
    "actual = scaler_Y.inverse_transform(actual_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TEST SET EVALUATION (Per Finger)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Finger':<15} {'MAE':<10} {'RMSE':<10} {'RÂ²':<10}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for i, finger in enumerate(finger_columns):\n",
    "    mae = mean_absolute_error(actual[:, i], predictions[:, i])\n",
    "    rmse = np.sqrt(mean_squared_error(actual[:, i], predictions[:, i]))\n",
    "    r2 = r2_score(actual[:, i], predictions[:, i])\n",
    "    print(f\"{finger:<15} {mae:<10.4f} {rmse:<10.4f} {r2:<10.4f}\")\n",
    "\n",
    "# Overall metrics\n",
    "overall_mae = mean_absolute_error(actual, predictions)\n",
    "overall_rmse = np.sqrt(mean_squared_error(actual, predictions))\n",
    "overall_r2 = r2_score(actual.flatten(), predictions.flatten())\n",
    "\n",
    "print(\"-\"*60)\n",
    "print(f\"{'OVERALL':<15} {overall_mae:<10.4f} {overall_rmse:<10.4f} {overall_r2:<10.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000ee862",
   "metadata": {},
   "source": [
    "## 12. Visualize Predictions\n",
    "\n",
    "Plot predicted vs actual finger positions on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d47cfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions for each finger\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, finger in enumerate(finger_columns):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot actual and predicted\n",
    "    ax.plot(actual[:, i], label='Actual', alpha=0.7, linewidth=2)\n",
    "    ax.plot(predictions[:, i], label='Predicted', linestyle='--', alpha=0.7, linewidth=2)\n",
    "    \n",
    "    # Calculate metrics for this finger\n",
    "    mae = mean_absolute_error(actual[:, i], predictions[:, i])\n",
    "    r2 = r2_score(actual[:, i], predictions[:, i])\n",
    "    \n",
    "    ax.set_title(f'{finger} (MAE: {mae:.4f}, RÂ²: {r2:.3f})', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Time Step', fontsize=10)\n",
    "    ax.set_ylabel('Position', fontsize=10)\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Finger Position Predictions on Test Set', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b190e9",
   "metadata": {},
   "source": [
    "## 13. Scatter Plots (Predicted vs Actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6043bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots to visualize prediction accuracy\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, finger in enumerate(finger_columns):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Scatter plot\n",
    "    ax.scatter(actual[:, i], predictions[:, i], alpha=0.5, s=20)\n",
    "    \n",
    "    # Perfect prediction line\n",
    "    min_val = min(actual[:, i].min(), predictions[:, i].min())\n",
    "    max_val = max(actual[:, i].max(), predictions[:, i].max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "    \n",
    "    # Calculate RÂ²\n",
    "    r2 = r2_score(actual[:, i], predictions[:, i])\n",
    "    \n",
    "    ax.set_xlabel('Actual', fontsize=10)\n",
    "    ax.set_ylabel('Predicted', fontsize=10)\n",
    "    ax.set_title(f'{finger} (RÂ² = {r2:.3f})', fontsize=11, fontweight='bold')\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Predicted vs Actual (Scatter Plots)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb47d1c",
   "metadata": {},
   "source": [
    "## 14. Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcaa92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and scalers\n",
    "model_save_path = \"../../models/lstm_model_final.pth\"\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'scaler_X_mean': scaler_X.mean_,\n",
    "    'scaler_X_scale': scaler_X.scale_,\n",
    "    'scaler_Y_mean': scaler_Y.mean_,\n",
    "    'scaler_Y_scale': scaler_Y.scale_,\n",
    "    'input_dim': input_dim,\n",
    "    'hidden_dim': hidden_dim,\n",
    "    'layer_dim': layer_dim,\n",
    "    'output_dim': output_dim,\n",
    "    'seq_length': seq_length,\n",
    "    'sensor_columns': sensor_columns,\n",
    "    'finger_columns': finger_columns\n",
    "}, model_save_path)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL SAVED\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model saved to: {model_save_path}\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"Overall test RÂ²: {overall_r2:.4f}\")\n",
    "print(\"\\nâœ“ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e15a85",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook implemented a complete LSTM pipeline for EMG to finger position prediction:\n",
    "\n",
    "1. âœ“ Data cleaning (removed corrupted rows)\n",
    "1. âœ“ Proper train/test split (80/20)\n",
    "1. âœ“ Data normalization (StandardScaler)\n",
    "1. âœ“ Sequence creation for temporal modeling\n",
    "1. âœ“ LSTM with dropout for regularization\n",
    "1. âœ“ Batch training with proper hidden state handling\n",
    "1. âœ“ Learning rate scheduling\n",
    "1. âœ“ Early stopping\n",
    "1. âœ“ Comprehensive evaluation metrics\n",
    "1. âœ“ Visualization of predictions\n",
    "\n",
    "The model should now produce meaningful predictions instead of flat lines!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Grip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
