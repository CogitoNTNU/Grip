{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2791cee",
   "metadata": {},
   "source": [
    "# LSTM Model for EMG to Finger Position Prediction\n",
    "\n",
    "This notebook trains an LSTM model to predict finger positions from EMG sensor data.\n",
    "\n",
    "## Pipeline Overview:\n",
    "\n",
    "1. Load and clean data\n",
    "1. Create temporal sequences\n",
    "1. Split into train/test sets (80/20)\n",
    "1. Train LSTM model with proper batching\n",
    "1. Evaluate on unseen test data\n",
    "1. Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db411870",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hei\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c32eb7d",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4028103d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Grip (Python 3.12.7)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f53521",
   "metadata": {},
   "source": [
    "## 2. Load and Clean Data\n",
    "\n",
    "Load CSV data and handle corrupted rows where sensor values are missing or misaligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d513753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "path = os.path.join(\"../../data\", \"integrated_data_20251030_195505.csv\")\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RAW DATA INFO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst 3 rows:\\n{df.head(3)}\")\n",
    "\n",
    "# Define required numeric columns (excluding timestamp and hand_label)\n",
    "numeric_columns = ['iteration', 'env0', 'raw0', 'env1', 'raw1', 'env2', 'raw2', 'env3', 'raw3', \n",
    "                   'thumb_tip', 'thumb_base', 'index', 'middle', 'ring', 'pinky']\n",
    "\n",
    "# Convert all numeric columns, coercing errors to NaN (handles corrupted rows)\n",
    "for col in numeric_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Remove rows with any NaN values in numeric columns\n",
    "df_clean = df.dropna(subset=numeric_columns)\n",
    "\n",
    "print(f\"\\nRows removed (corrupted/missing data): {len(df) - len(df_clean)}\")\n",
    "print(f\"Clean data shape: {df_clean.shape}\")\n",
    "\n",
    "# Extract only numeric data (drop timestamp and hand_label)\n",
    "data = df_clean[numeric_columns].values.astype(np.float32)\n",
    "\n",
    "print(f\"\\nFinal numeric data shape: {data.shape}\")\n",
    "print(f\"Data statistics:\\n{pd.DataFrame(data, columns=numeric_columns).describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6f8104",
   "metadata": {},
   "source": [
    "## 3. Prepare Data for LSTM\n",
    "\n",
    "Separate sensor inputs from finger outputs and create temporal sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ff884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sensor (input) and finger (output) columns\n",
    "sensor_columns = ['env0', 'raw0', 'env1', 'raw1', 'env2', 'raw2', 'env3', 'raw3']\n",
    "finger_columns = ['thumb_tip', 'thumb_base', 'index', 'middle', 'ring', 'pinky']\n",
    "\n",
    "# Get column indices in the data array\n",
    "sensor_indices = [numeric_columns.index(col) for col in sensor_columns]\n",
    "finger_indices = [numeric_columns.index(col) for col in finger_columns]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATA CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Sensor columns (inputs): {sensor_columns}\")\n",
    "print(f\"Sensor indices: {sensor_indices}\")\n",
    "print(f\"Number of input features: {len(sensor_indices)}\")\n",
    "print(f\"\\nFinger columns (outputs): {finger_columns}\")\n",
    "print(f\"Finger indices: {finger_indices}\")\n",
    "print(f\"Number of output features: {len(finger_indices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594b6750",
   "metadata": {},
   "source": [
    "## 4. Create Temporal Sequences\n",
    "\n",
    "LSTMs need sequences of data. We'll create sliding windows of sensor readings to predict the next finger position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99a23ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length):\n",
    "    \"\"\"\n",
    "    Create sequences for LSTM training.\n",
    "    \n",
    "    Args:\n",
    "        data: numpy array of shape (num_samples, num_features)\n",
    "        seq_length: length of input sequence\n",
    "    \n",
    "    Returns:\n",
    "        X: sequences of shape (num_sequences, seq_length, num_features)\n",
    "        y: targets of shape (num_sequences, num_features)\n",
    "    \"\"\"\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:i + seq_length, :]  # Sequence of seq_length time steps\n",
    "        y = data[i + seq_length, :]    # Next time step (target)\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Create sequences\n",
    "seq_length = 15\n",
    "X, y = create_sequences(data, seq_length)\n",
    "\n",
    "print(f\"\\nSequence length: {seq_length} time steps\")\n",
    "print(f\"Total sequences created: {len(X)}\")\n",
    "print(f\"X shape: {X.shape} (num_sequences, seq_length, num_features)\")\n",
    "print(f\"y shape: {y.shape} (num_sequences, num_features)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844959d6",
   "metadata": {},
   "source": [
    "## 5. Train/Test Split and Feature Selection\n",
    "\n",
    "Split data temporally (80/20) and separate sensor inputs from finger outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e25aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data temporally (80% train, 20% test)\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(X) * split_ratio)\n",
    "\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAIN/TEST SPLIT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total sequences: {len(X)}\")\n",
    "print(f\"Training sequences: {len(X_train)} ({split_ratio*100:.0f}%)\")\n",
    "print(f\"Testing sequences: {len(X_test)} ({(1-split_ratio)*100:.0f}%)\")\n",
    "\n",
    "# Extract sensor and finger features\n",
    "trainX = torch.tensor(X_train[:, :, sensor_indices], dtype=torch.float32)\n",
    "trainY = torch.tensor(y_train[:, finger_indices], dtype=torch.float32)\n",
    "testX = torch.tensor(X_test[:, :, sensor_indices], dtype=torch.float32)\n",
    "testY = torch.tensor(y_test[:, finger_indices], dtype=torch.float32)\n",
    "\n",
    "print(f\"\\nTraining data:\")\n",
    "print(f\"  trainX: {trainX.shape} (sequences, seq_length, input_features)\")\n",
    "print(f\"  trainY: {trainY.shape} (sequences, output_features)\")\n",
    "print(f\"\\nTesting data:\")\n",
    "print(f\"  testX: {testX.shape}\")\n",
    "print(f\"  testY: {testY.shape}\")\n",
    "\n",
    "print(f\"\\nInput features: {len(sensor_indices)}\")\n",
    "print(f\"Output features: {len(finger_indices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d3d316",
   "metadata": {},
   "source": [
    "## 6. Normalize Data\n",
    "\n",
    "Normalize inputs and outputs for better training stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34fe002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize sensor data (inputs)\n",
    "scaler_X = StandardScaler()\n",
    "trainX_reshaped = trainX.reshape(-1, trainX.shape[-1]).numpy()\n",
    "trainX_scaled = scaler_X.fit_transform(trainX_reshaped).reshape(trainX.shape)\n",
    "trainX = torch.tensor(trainX_scaled, dtype=torch.float32)\n",
    "\n",
    "testX_reshaped = testX.reshape(-1, testX.shape[-1]).numpy()\n",
    "testX_scaled = scaler_X.transform(testX_reshaped).reshape(testX.shape)\n",
    "testX = torch.tensor(testX_scaled, dtype=torch.float32)\n",
    "\n",
    "# Normalize finger data (outputs)\n",
    "scaler_Y = StandardScaler()\n",
    "trainY_scaled = scaler_Y.fit_transform(trainY.numpy())\n",
    "trainY = torch.tensor(trainY_scaled, dtype=torch.float32)\n",
    "\n",
    "testY_scaled = scaler_Y.transform(testY.numpy())\n",
    "testY = torch.tensor(testY_scaled, dtype=torch.float32)\n",
    "\n",
    "print(\"✓ Data normalized using StandardScaler\")\n",
    "print(f\"  Sensor mean: {scaler_X.mean_[:3].round(2)} (first 3 features)\")\n",
    "print(f\"  Sensor std: {scaler_X.scale_[:3].round(2)} (first 3 features)\")\n",
    "print(f\"  Finger mean: {scaler_Y.mean_[:3].round(2)} (first 3 features)\")\n",
    "print(f\"  Finger std: {scaler_Y.scale_[:3].round(2)} (first 3 features)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8089483",
   "metadata": {},
   "source": [
    "## 7. Define LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75474591",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout=0.2):\n",
    "        \"\"\"\n",
    "        LSTM model for sequence prediction.\n",
    "        \n",
    "        Args:\n",
    "            input_dim: Number of input features\n",
    "            hidden_dim: Number of hidden units in LSTM\n",
    "            layer_dim: Number of LSTM layers\n",
    "            output_dim: Number of output features\n",
    "            dropout: Dropout probability for regularization\n",
    "        \"\"\"\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # LSTM layer with dropout between layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim, \n",
    "            hidden_dim, \n",
    "            layer_dim, \n",
    "            batch_first=True,\n",
    "            dropout=dropout if layer_dim > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Fully connected output layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden and cell states (set to zeros)\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
    "        \n",
    "        # LSTM forward pass\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Take the last time step output\n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        # Apply dropout\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Model hyperparameters\n",
    "input_dim = len(sensor_indices)  # Number of sensor features\n",
    "hidden_dim = 128                  # Number of hidden units\n",
    "layer_dim = 2                     # Number of LSTM layers\n",
    "output_dim = len(finger_indices)  # Number of finger features\n",
    "dropout = 0.2                     # Dropout probability\n",
    "\n",
    "# Initialize model\n",
    "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim, dropout)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL ARCHITECTURE\")\n",
    "print(\"=\"*60)\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18961e3",
   "metadata": {},
   "source": [
    "## 8. Setup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7978df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min', \n",
    "    factor=0.5, \n",
    "    patience=10, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Create DataLoader for batching\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(trainX, trainY)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Loss function: MSELoss\")\n",
    "print(f\"Optimizer: Adam (lr=0.001)\")\n",
    "print(f\"Scheduler: ReduceLROnPlateau (factor=0.5, patience=10)\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Batches per epoch: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66b1670",
   "metadata": {},
   "source": [
    "## 9. Train Model\n",
    "\n",
    "Train with proper batching, validation tracking, and early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb95968",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "patience = 20\n",
    "patience_counter = 0\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING STARTED\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for batch_X, batch_Y in train_loader:\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, batch_Y)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Average training loss\n",
    "    avg_train_loss = epoch_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(testX)\n",
    "        val_loss = criterion(val_outputs, testY)\n",
    "        val_losses.append(val_loss.item())\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Early stopping check\n",
    "    if val_loss.item() < best_val_loss:\n",
    "        best_val_loss = val_loss.item()\n",
    "        patience_counter = 0\n",
    "        # Save best model\n",
    "        torch.save(model.state_dict(), \"../../models/best_lstm_model.pth\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "              f'Train Loss: {avg_train_loss:.4f}, '\n",
    "              f'Val Loss: {val_loss.item():.4f}, '\n",
    "              f'Best Val: {best_val_loss:.4f}')\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"\\nEarly stopping triggered at epoch {epoch+1}\")\n",
    "        print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "        break\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETED\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Final train loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Final validation loss: {val_losses[-1]:.4f}\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load(\"../../models/best_lstm_model.pth\"))\n",
    "print(\"\\n✓ Best model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d524c8",
   "metadata": {},
   "source": [
    "## 10. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8d873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.plot(train_losses, label='Train Loss', alpha=0.8, linewidth=2)\n",
    "plt.plot(val_losses, label='Validation Loss', alpha=0.8, linewidth=2)\n",
    "plt.axhline(y=best_val_loss, color='r', linestyle='--', label=f'Best Val Loss ({best_val_loss:.4f})', alpha=0.5)\n",
    "\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss (MSE)', fontsize=12)\n",
    "plt.title('Training vs Validation Loss', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check for overfitting\n",
    "final_gap = val_losses[-1] - train_losses[-1]\n",
    "if final_gap > 0.1:\n",
    "    print(f\"⚠ Warning: Possible overfitting detected (gap: {final_gap:.4f})\")\n",
    "else:\n",
    "    print(f\"✓ Good generalization (train-val gap: {final_gap:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c872df7",
   "metadata": {},
   "source": [
    "## 11. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44abf160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions_scaled = model(testX).numpy()\n",
    "    actual_scaled = testY.numpy()\n",
    "\n",
    "# Inverse transform to original scale\n",
    "predictions = scaler_Y.inverse_transform(predictions_scaled)\n",
    "actual = scaler_Y.inverse_transform(actual_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TEST SET EVALUATION (Per Finger)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Finger':<15} {'MAE':<10} {'RMSE':<10} {'R²':<10}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for i, finger in enumerate(finger_columns):\n",
    "    mae = mean_absolute_error(actual[:, i], predictions[:, i])\n",
    "    rmse = np.sqrt(mean_squared_error(actual[:, i], predictions[:, i]))\n",
    "    r2 = r2_score(actual[:, i], predictions[:, i])\n",
    "    print(f\"{finger:<15} {mae:<10.4f} {rmse:<10.4f} {r2:<10.4f}\")\n",
    "\n",
    "# Overall metrics\n",
    "overall_mae = mean_absolute_error(actual, predictions)\n",
    "overall_rmse = np.sqrt(mean_squared_error(actual, predictions))\n",
    "overall_r2 = r2_score(actual.flatten(), predictions.flatten())\n",
    "\n",
    "print(\"-\"*60)\n",
    "print(f\"{'OVERALL':<15} {overall_mae:<10.4f} {overall_rmse:<10.4f} {overall_r2:<10.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000ee862",
   "metadata": {},
   "source": [
    "## 12. Visualize Predictions\n",
    "\n",
    "Plot predicted vs actual finger positions on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d47cfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions for each finger\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, finger in enumerate(finger_columns):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot actual and predicted\n",
    "    ax.plot(actual[:, i], label='Actual', alpha=0.7, linewidth=2)\n",
    "    ax.plot(predictions[:, i], label='Predicted', linestyle='--', alpha=0.7, linewidth=2)\n",
    "    \n",
    "    # Calculate metrics for this finger\n",
    "    mae = mean_absolute_error(actual[:, i], predictions[:, i])\n",
    "    r2 = r2_score(actual[:, i], predictions[:, i])\n",
    "    \n",
    "    ax.set_title(f'{finger} (MAE: {mae:.4f}, R²: {r2:.3f})', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Time Step', fontsize=10)\n",
    "    ax.set_ylabel('Position', fontsize=10)\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Finger Position Predictions on Test Set', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b190e9",
   "metadata": {},
   "source": [
    "## 13. Scatter Plots (Predicted vs Actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6043bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots to visualize prediction accuracy\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, finger in enumerate(finger_columns):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Scatter plot\n",
    "    ax.scatter(actual[:, i], predictions[:, i], alpha=0.5, s=20)\n",
    "    \n",
    "    # Perfect prediction line\n",
    "    min_val = min(actual[:, i].min(), predictions[:, i].min())\n",
    "    max_val = max(actual[:, i].max(), predictions[:, i].max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "    \n",
    "    # Calculate R²\n",
    "    r2 = r2_score(actual[:, i], predictions[:, i])\n",
    "    \n",
    "    ax.set_xlabel('Actual', fontsize=10)\n",
    "    ax.set_ylabel('Predicted', fontsize=10)\n",
    "    ax.set_title(f'{finger} (R² = {r2:.3f})', fontsize=11, fontweight='bold')\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Predicted vs Actual (Scatter Plots)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb47d1c",
   "metadata": {},
   "source": [
    "## 14. Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcaa92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and scalers\n",
    "model_save_path = \"../../models/lstm_model_final.pth\"\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'scaler_X_mean': scaler_X.mean_,\n",
    "    'scaler_X_scale': scaler_X.scale_,\n",
    "    'scaler_Y_mean': scaler_Y.mean_,\n",
    "    'scaler_Y_scale': scaler_Y.scale_,\n",
    "    'input_dim': input_dim,\n",
    "    'hidden_dim': hidden_dim,\n",
    "    'layer_dim': layer_dim,\n",
    "    'output_dim': output_dim,\n",
    "    'seq_length': seq_length,\n",
    "    'sensor_columns': sensor_columns,\n",
    "    'finger_columns': finger_columns\n",
    "}, model_save_path)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL SAVED\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model saved to: {model_save_path}\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"Overall test R²: {overall_r2:.4f}\")\n",
    "print(\"\\n✓ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e15a85",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook implemented a complete LSTM pipeline for EMG to finger position prediction:\n",
    "\n",
    "1. ✓ Data cleaning (removed corrupted rows)\n",
    "1. ✓ Proper train/test split (80/20)\n",
    "1. ✓ Data normalization (StandardScaler)\n",
    "1. ✓ Sequence creation for temporal modeling\n",
    "1. ✓ LSTM with dropout for regularization\n",
    "1. ✓ Batch training with proper hidden state handling\n",
    "1. ✓ Learning rate scheduling\n",
    "1. ✓ Early stopping\n",
    "1. ✓ Comprehensive evaluation metrics\n",
    "1. ✓ Visualization of predictions\n",
    "\n",
    "The model should now produce meaningful predictions instead of flat lines!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Grip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
